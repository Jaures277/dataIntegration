services:
  zookeeper:
    image: bitnami/zookeeper:3.8
    container_name: zookeeper
    ports:
      - "2181:2181"
    environment:
      - ALLOW_ANONYMOUS_LOGIN=yes

  kafka:
    image: bitnami/kafka:3.4
    container_name: kafka
    ports:
      - "9092:9092"
    environment:
      - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=PLAINTEXT:PLAINTEXT
      - KAFKA_CFG_LISTENERS=PLAINTEXT://0.0.0.0:9092
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092
      - KAFKA_CFG_BROKER_ID=1
      - KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE=true
      - ALLOW_PLAINTEXT_LISTENER=yes
    depends_on:
      - zookeeper

  spark-master:
    image: bitnami/spark:3.5.1
    container_name: spark-master
    environment:
      - SPARK_MODE=master
    ports:
      - "7077:7077"
      - "8080:8080"

  spark-worker:
    image: bitnami/spark:3.5.1
    container_name: spark-worker
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
    depends_on:
      - spark-master

  namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
    container_name: namenode
    ports:
      - "9870:9870"     # Web UI
      - "9000:9000"     # RPC
    environment:
      - CLUSTER_NAME=hadoop
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
      - HDFS_NAMENODE_HTTP_ADDRESS=0.0.0.0:9870
      - HDFS_NAMENODE_RPC_ADDRESS=namenode:9000
    volumes:
      - hdfs_namenode:/hadoop/dfs/name

  datanode:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: datanode
    ports:
      - "9864:9864"
    environment:
      - CLUSTER_NAME=hadoop
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
      - HDFS_DATANODE_HOSTNAME=datanode
    volumes:
      - hdfs_datanode:/hadoop/dfs/data
    depends_on:
      - namenode

  kafdrop:
    image: obsidiandynamics/kafdrop
    container_name: kafdrop
    ports:
      - "9001:9000"
    environment:
      - KAFKA_BROKERCONNECT=kafka:9092
    depends_on:
      - kafka

  spark-producer:
    build:
      context: .
      dockerfile: Dockerfile.producer
    container_name: spark-producer
    depends_on:
      - kafka
      - namenode
    volumes:
      - ./data:/app/data
    networks:
      - default

  postgres:
    image: postgres:15
    container_name: postgres
    environment:
      POSTGRES_USER: admin
      POSTGRES_PASSWORD: adminpass
      POSTGRES_DB: pret_etudiant_db
    ports:
      - "5433:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    networks:
      - default

  spark-consumer:
    build:
      context: .
      dockerfile: Dockerfile.spark
    depends_on:
      - kafka
      - postgres
      - namenode  # important si tu veux accéder à HDFS
    networks:
      - default
    volumes:
      - ./spark:/app  # <-- Montre ton dossier avec le script
      - ./spark/conf/core-site.xml:/opt/bitnami/spark/conf/core-site.xml:ro
      - ./spark/conf/hdfs-site.xml:/opt/bitnami/spark/conf/hdfs-site.xml:ro
      - spark-checkpoints:/tmp/spark-checkpoint  # ✅ nom cohérent avec le script
    environment:
      - USER=spark
      - HADOOP_CONF_DIR=/opt/bitnami/spark/conf
      - SPARK_SUBMIT_OPTIONS=--conf spark.jars.ivy=/opt/bitnami/spark/ivy
    entrypoint: [ "/bin/bash", "-c" ]
    command: spark-submit /app/step1_kafka_reader.py
  

  cleaner:
    build:
      context: .
      dockerfile: Dockerfile.cleaner
    volumes:
      - ./data:/app/data
    depends_on:
      - namenode
    networks:
      - default

  spark-metrics:
    build:
      context: .
      dockerfile: Dockerfile.spark  # Ton Dockerfile avec cron
    container_name: spark-metrics
    depends_on:
      - kafka
      - namenode
    volumes:
      - ./app:/app                         # Pour les scripts locaux
      - hdfs_namenode:/hadoop/dfs/name     # Accès HDFS si nécessaire
    environment:
      - HADOOP_USER_NAME=spark
      - USER=spark
    restart: unless-stopped


volumes:
  hdfs_namenode:
  hdfs_datanode:
  postgres_data:
  spark-checkpoints:
